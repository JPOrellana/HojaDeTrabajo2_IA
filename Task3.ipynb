{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "## Proceso de Decisión de Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Semilla aleatoria para reproductibilidad\n",
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entorno Frozen Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El frozen lake quedo de la siguiente manera:\n",
      "[['S' 'F' 'F' 'F']\n",
      " ['F' 'H' 'F' 'F']\n",
      " ['F' 'F' 'F' 'F']\n",
      " ['F' 'F' 'F' 'G']]\n"
     ]
    }
   ],
   "source": [
    "class FrozenLakeEnvironment:\n",
    "    def __init__(self):\n",
    "        self.grid_size = 4\n",
    "        self.states = ['S', 'F', 'H', 'G']  # Start, Frozen, Hole, Goal\n",
    "        self.grid = np.full((self.grid_size, self.grid_size), 'F')  # Colocar las celdas como frozen\n",
    "        self.env = None\n",
    "        self.desc = None\n",
    "        # Elegir la posicion inicial aleatoria y asignar la meta en la esquina opuesta\n",
    "        start_positions = [(0, 0), (0, self.grid_size-1), (self.grid_size-1, 0), (self.grid_size-1, self.grid_size-1)]\n",
    "        start_pos = start_positions[np.random.choice(len(start_positions))]\n",
    "        goal_pos = (self.grid_size-1-start_pos[0], self.grid_size-1-start_pos[1])\n",
    "        self.grid[start_pos] = 'S'\n",
    "        self.grid[goal_pos] = 'G'\n",
    "        self.start_pos = start_pos\n",
    "        self.goal_pos = goal_pos\n",
    "        \n",
    "    def _place_holes(self):\n",
    "        # Determinar los hoyos y sus posiciones\n",
    "        num_holes = np.random.randint(1, 4)\n",
    "        \n",
    "        available_positions = [(i, j) for i in range(self.grid_size) for j in range(self.grid_size)\n",
    "                               if self.grid[i, j] == 'F']\n",
    "        \n",
    "        hole_positions = np.random.choice(range(len(available_positions)), size=num_holes, replace=False)\n",
    "        for pos_index in hole_positions:\n",
    "            self.grid[available_positions[pos_index]] = 'H'\n",
    "\n",
    "    def setup_environment(self):\n",
    "        self._place_holes()\n",
    "\n",
    "# Inicializar el entorno\n",
    "frozen_lake = FrozenLakeEnvironment()\n",
    "frozen_lake.setup_environment()\n",
    "\n",
    "print(\"El frozen lake quedo de la siguiente manera:\")\n",
    "print(frozen_lake.grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolver el Frozen Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el estado (0, 0): la política óptima es: Down\n",
      "En el estado (0, 1): la política óptima es: Right\n",
      "En el estado (0, 2): la política óptima es: Down\n",
      "En el estado (0, 3): la política óptima es: Down\n",
      "En el estado (1, 0): la política óptima es: Down\n",
      "En el estado (1, 1): la política óptima es: Up\n",
      "En el estado (1, 2): la política óptima es: Down\n",
      "En el estado (1, 3): la política óptima es: Down\n",
      "En el estado (2, 0): la política óptima es: Down\n",
      "En el estado (2, 1): la política óptima es: Down\n",
      "En el estado (2, 2): la política óptima es: Down\n",
      "En el estado (2, 3): la política óptima es: Down\n",
      "En el estado (3, 0): la política óptima es: Right\n",
      "En el estado (3, 1): la política óptima es: Right\n",
      "En el estado (3, 2): la política óptima es: Right\n",
      "En el estado (3, 3): la política óptima es: Up\n"
     ]
    }
   ],
   "source": [
    "# Definir el algoritmo para encontrar la política óptima\n",
    "def find_optimal_policy(env, gamma=0.99, theta=1e-8):\n",
    "    num_states = env.grid_size ** 2\n",
    "    num_actions = 4  # Up, Down, Left, Right\n",
    "    value_table = np.zeros(num_states)\n",
    "    rewards = np.full((num_states, num_actions), -1.0)  # Recompensas por defecto\n",
    "    transitions = np.zeros((num_states, num_actions, num_states))  # Probabilidades de transición\n",
    "\n",
    "    # Establecer recompensas y transiciones\n",
    "    for x in range(env.grid_size):\n",
    "        for y in range(env.grid_size):\n",
    "            current_state = x * env.grid_size + y\n",
    "            for action in range(num_actions):\n",
    "                new_x, new_y = x, y\n",
    "                if env.grid[x, y] in ['G', 'H']:  # No hay transiciones desde estados terminales\n",
    "                    transitions[current_state, action, current_state] = 1.0\n",
    "                    rewards[current_state, action] = 0.0\n",
    "                else:\n",
    "                    if action == 0 and x > 0:  # Arriba\n",
    "                        new_x -= 1\n",
    "                    elif action == 1 and x < env.grid_size - 1:  # Abajo\n",
    "                        new_x += 1\n",
    "                    elif action == 2 and y > 0:  # Izquierda\n",
    "                        new_y -= 1\n",
    "                    elif action == 3 and y < env.grid_size - 1:  # Derecha\n",
    "                        new_y += 1\n",
    "                    new_state = new_x * env.grid_size + new_y\n",
    "                    transitions[current_state, action, new_state] = 1.0\n",
    "                    if env.grid[new_x, new_y] == 'G':\n",
    "                        rewards[current_state, action] = 100.0\n",
    "                    elif env.grid[new_x, new_y] == 'H':\n",
    "                        rewards[current_state, action] = -100.0\n",
    "\n",
    "    # Iteración de valor\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for state in range(num_states):\n",
    "            v = value_table[state]\n",
    "            value_table[state] = max([sum([transitions[state, action, next_state] * \n",
    "                                           (rewards[state, action] + gamma * value_table[next_state]) \n",
    "                                           for next_state in range(num_states)]) \n",
    "                                      for action in range(num_actions)])\n",
    "            delta = max(delta, abs(v - value_table[state]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    # Extraer política óptima\n",
    "    policy = np.zeros(num_states, dtype=int)\n",
    "    for state in range(num_states):\n",
    "        action_values = np.zeros(num_actions)\n",
    "        for action in range(num_actions):\n",
    "            for next_state in range(num_states):\n",
    "                action_values[action] += transitions[state, action, next_state] * \\\n",
    "                                         (rewards[state, action] + gamma * value_table[next_state])\n",
    "        policy[state] = np.argmax(action_values)\n",
    "\n",
    "    return policy\n",
    "\n",
    "# Convertir la política en acciones legibles\n",
    "def policy_to_directions(policy, grid_size):\n",
    "    directions = ['Up', 'Down', 'Left', 'Right']\n",
    "    policy_directions = np.array([directions[action] for action in policy]).reshape(grid_size, grid_size)\n",
    "    return policy_directions\n",
    "\n",
    "optimal_policy = find_optimal_policy(frozen_lake)\n",
    "policy_directions = policy_to_directions(optimal_policy, frozen_lake.grid_size)\n",
    "\n",
    "# Mostrar la política óptima\n",
    "for i in range(frozen_lake.grid_size):\n",
    "    for j in range(frozen_lake.grid_size):\n",
    "        print(f\"En el estado ({i}, {j}): la política óptima es: {policy_directions[i, j]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
